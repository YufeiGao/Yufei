{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data process(Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class data_proc():\n",
    "    \n",
    "    def process_zip():\n",
    "        #dealing with zipcode\n",
    "        zip_data=pd.read_csv('ZIP.csv')\n",
    "        zip_data['Zip']=zip_data['Zip'].astype(str)\n",
    "        for i in range(len(zip_data['Zip'])):\n",
    "            if len(zip_data['Zip'][i])==4:\n",
    "                zip_data['Zip'][i]='0'+zip_data['Zip'][i]\n",
    "        zip_data['Zip']=[zip_data['Zip'][i][0:3] for i in range(len(zip_data))] \n",
    "        zip_data.iloc[:,-3:]=zip_data[['Median','Mean','Pop']].apply(lambda x: x.str.replace(',',''))\n",
    "        for i in range(1,4):\n",
    "            zip_data.iloc[:,-i]=pd.to_numeric(zip_data.iloc[:,-i],errors='coerce')\n",
    "        zip_data['weight']=zip_data['Pop']/zip_data.groupby('Zip')['Pop'].transform(sum)\n",
    "        zip_data['new_mean']=zip_data['Mean']*zip_data['weight']\n",
    "        zip_data['new_median']=zip_data['Median']*zip_data['weight']\n",
    "        zip_new=pd.DataFrame()\n",
    "        zip_new=zip_data.groupby('Zip')['new_mean','new_median'].sum()\n",
    "        return zip_new\n",
    "        \n",
    "    def readcsv():\n",
    "        LARGE_FILE = \"loan_data_no_current_converted.csv\"\n",
    "        CHUNKSIZE = 100000 # processing 100,000 rows at a time\n",
    "        reader = pd.read_csv(LARGE_FILE, chunksize=CHUNKSIZE, low_memory=False)\n",
    "        frames = []\n",
    "        for df in reader:\n",
    "            frames.append(df)\n",
    "        loan_data = pd.concat(frames)\n",
    "        return loan_data   \n",
    "    def cleaning(df,zip_new,keep_desc=True,categorical_to_binary=True):\n",
    "        #find the drop_list in kaggle\n",
    "        whole_list=[]\n",
    "        for key, value in df.iteritems():\n",
    "            whole_list.append(key)\n",
    "        #kaggle features\n",
    "        keep_list=[ 'loan_amnt', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'loan_status', 'pymnt_plan',  \n",
    "                    'purpose','zip_code', 'dti', 'delinq_2yrs','inq_last_6mths', 'mths_since_last_delinq', \n",
    "                    'mths_since_last_record', 'open_acc','pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status', 'total_pymnt',\n",
    "                    'total_rec_prncp','total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', \n",
    "                    'last_pymnt_amnt', 'next_pymnt_d', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', \n",
    "                    'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'acc_now_delinq', \n",
    "                    'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', \n",
    "                    'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', \n",
    "                    'total_cu_tl', 'inq_last_12m']\n",
    "        drop_list=[]\n",
    "        for key in whole_list:\n",
    "            if key not in keep_list:\n",
    "                drop_list.append(key)\n",
    "        #drop features not in kaggle\n",
    "        df.drop(drop_list,inplace=True,axis=1,errors='ignore')\n",
    "        #deal with percentage mark\n",
    "        df['revol_util']=df['revol_util'].replace('%','',regex=True).astype('float')/100\n",
    "        #merge zipcode with census data\n",
    "        df['zip_code']=df['zip_code'].apply(lambda x: x[:3])\n",
    "        df=df.join(zip_new,on='zip_code')\n",
    "        df.drop('zip_code',inplace=True,axis=1)\n",
    "        #drop the observation that was missing for ALL field\n",
    "        df=df.dropna(axis=0,how='all')\n",
    "        #drop the features for which greater than 10% of the loans were missing data for\n",
    "        num_rows=df.count(axis=0)\n",
    "        df=df.iloc[:,(num_rows>=0.9*len(df)).tolist()]\n",
    "        #drop the observation that was missing for any field\n",
    "        df=df.dropna(axis=0,how='any')\n",
    "        #label the dataset to create y\n",
    "        y=df['loan_status'].replace(8,0)\n",
    "        y=y.replace(1,1)\n",
    "        y=y.replace(2,1)\n",
    "        y=y.replace(3,0)\n",
    "        y=y.replace(4,0)\n",
    "        y=y.replace(5,0)\n",
    "        y=y.replace(6,0)\n",
    "        y=y.replace(7,0)\n",
    "        df=df.drop(['loan_status'],axis=1)    \n",
    "        return df,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data process(Multi-Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Multi_data_proc():\n",
    "    \n",
    "    def process_zip():\n",
    "        #dealing with zipcode\n",
    "        zip_data=pd.read_csv('ZIP.csv')\n",
    "        zip_data['Zip']=zip_data['Zip'].astype(str)\n",
    "        for i in range(len(zip_data['Zip'])):\n",
    "            if len(zip_data['Zip'][i])==4:\n",
    "                zip_data['Zip'][i]='0'+zip_data['Zip'][i]\n",
    "        zip_data['Zip']=[zip_data['Zip'][i][0:3] for i in range(len(zip_data))] \n",
    "        zip_data.iloc[:,-3:]=zip_data[['Median','Mean','Pop']].apply(lambda x: x.str.replace(',',''))\n",
    "        for i in range(1,4):\n",
    "            zip_data.iloc[:,-i]=pd.to_numeric(zip_data.iloc[:,-i],errors='coerce')\n",
    "        zip_data['weight']=zip_data['Pop']/zip_data.groupby('Zip')['Pop'].transform(sum)\n",
    "        zip_data['new_mean']=zip_data['Mean']*zip_data['weight']\n",
    "        zip_data['new_median']=zip_data['Median']*zip_data['weight']\n",
    "        zip_new=pd.DataFrame()\n",
    "        zip_new=zip_data.groupby('Zip')['new_mean','new_median'].sum()\n",
    "        return zip_new\n",
    "        \n",
    "    def readcsv():\n",
    "        LARGE_FILE = \"loan_data_no_current_converted.csv\"\n",
    "        CHUNKSIZE = 100000 # processing 100,000 rows at a time\n",
    "        reader = pd.read_csv(LARGE_FILE, chunksize=CHUNKSIZE, low_memory=False)\n",
    "        frames = []\n",
    "        for df in reader:\n",
    "            frames.append(df)\n",
    "        loan_data = pd.concat(frames)\n",
    "        return loan_data   \n",
    "    def cleaning(df,zip_new,keep_desc=True,categorical_to_binary=True):\n",
    "        #find the drop_list in kaggle\n",
    "        whole_list=[]\n",
    "        for key, value in df.iteritems():\n",
    "            whole_list.append(key)\n",
    "        #kaggle features\n",
    "        keep_list=[ 'loan_amnt', 'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'loan_status', 'pymnt_plan',  \n",
    "                    'purpose','zip_code', 'dti', 'delinq_2yrs','inq_last_6mths', 'mths_since_last_delinq', \n",
    "                    'mths_since_last_record', 'open_acc','pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status', 'total_pymnt',\n",
    "                    'total_rec_prncp','total_rec_int', 'total_rec_late_fee', 'recoveries', 'collection_recovery_fee', \n",
    "                    'last_pymnt_amnt', 'next_pymnt_d', 'collections_12_mths_ex_med', 'mths_since_last_major_derog', \n",
    "                    'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint', 'verification_status_joint', 'acc_now_delinq', \n",
    "                    'tot_coll_amt', 'tot_cur_bal', 'open_acc_6m', 'open_il_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il', \n",
    "                    'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_rev_hi_lim', 'inq_fi', \n",
    "                    'total_cu_tl', 'inq_last_12m']\n",
    "        drop_list=[]\n",
    "        for key in whole_list:\n",
    "            if key not in keep_list:\n",
    "                drop_list.append(key)\n",
    "        #drop features not in kaggle\n",
    "        df.drop(drop_list,inplace=True,axis=1,errors='ignore')\n",
    "        #deal with percentage mark\n",
    "        df['revol_util']=df['revol_util'].replace('%','',regex=True).astype('float')/100\n",
    "        #merge zipcode with census data\n",
    "        df['zip_code']=df['zip_code'].apply(lambda x: x[:3])\n",
    "        df=df.join(zip_new,on='zip_code')\n",
    "        df.drop('zip_code',inplace=True,axis=1)\n",
    "        #drop the observation that was missing for ALL field\n",
    "        df=df.dropna(axis=0,how='all')\n",
    "        #drop the features for which greater than 10% of the loans were missing data for\n",
    "        num_rows=df.count(axis=0)\n",
    "        df=df.iloc[:,(num_rows>=0.9*len(df)).tolist()]\n",
    "        #drop the observation that was missing for any field\n",
    "        df=df.dropna(axis=0,how='any')\n",
    "        #label the dataset to create y\n",
    "        #0:fully paid, does not meet policy:fully paid\n",
    "        #1: Grace period\n",
    "        #2:Late(16-30days),Late(31-120 days)\n",
    "        #3:\"Does not meet the credit policy. Status:Charged Off\",default,charge of\n",
    "        y=df['loan_status'].replace(1,0)\n",
    "        y=y.replace(2,0)\n",
    "        y=y.replace(5,2)\n",
    "        y=y.replace(6,2)\n",
    "        y=y.replace(4,1)\n",
    "        y=y.replace(3,3)\n",
    "        y=y.replace(7,3)\n",
    "        y=y.replace(8,3)\n",
    "        df=df.drop(['loan_status'],axis=1)    \n",
    "        return df,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run data_proc class to get Binary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipdata = data_proc.process_zip()\n",
    "df = data_proc.readcsv()\n",
    "x,y = data_proc.cleaning(df,zipdata,keep_desc=False,categorical_to_binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt\n",
      "emp_length\n",
      "home_ownership\n",
      "annual_inc\n",
      "verification_status\n",
      "pymnt_plan\n",
      "purpose\n",
      "dti\n",
      "delinq_2yrs\n",
      "inq_last_6mths\n",
      "open_acc\n",
      "pub_rec\n",
      "revol_bal\n",
      "revol_util\n",
      "total_acc\n",
      "initial_list_status\n",
      "total_pymnt\n",
      "total_rec_prncp\n",
      "total_rec_int\n",
      "total_rec_late_fee\n",
      "recoveries\n",
      "collection_recovery_fee\n",
      "last_pymnt_amnt\n",
      "collections_12_mths_ex_med\n",
      "policy_code\n",
      "application_type\n",
      "acc_now_delinq\n",
      "tot_coll_amt\n",
      "tot_cur_bal\n",
      "total_rev_hi_lim\n",
      "new_mean\n",
      "new_median\n"
     ]
    }
   ],
   "source": [
    "for key, value in x.iteritems():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Mutli-class process to get multi-class dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_multi,y_multi = Multi_data_proc.cleaning(df,zipdata,keep_desc=False,categorical_to_binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Logistic Regression(Ridge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Binary logistic regression\n",
    "class log_reg():\n",
    "    # Evaluate the model by splitting into train and test sets\n",
    "    def split(x,y,rand=0):\n",
    "        \n",
    "        y = np.ravel(y)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25,random_state=rand)\n",
    "        \n",
    "        return x_train, x_test, y_train, y_test \n",
    "    #we need to add validation dataset here\n",
    "    \n",
    "    # Find binary column method one\n",
    "    def bool_cols(df,isbool=True):\n",
    "        bool_cols=[]\n",
    "        for col in df:\n",
    "            if isbool==True:\n",
    "                if df[col].dropna().value_counts().index.isin([0,1]).all():\n",
    "                    bool_cols.append(col)\n",
    "            else:\n",
    "                if not df[col].dropna().value_counts().index.isin([0,1]).all():\n",
    "                    bool_cols.append(col)\n",
    "        return bool_cols\n",
    "    # this above step is to facilitate normalization later\n",
    "    # method two\n",
    "    def not_bi(x):\n",
    "        not_bi=[]\n",
    "        for i in list(x):\n",
    "            u=x[i].unique()\n",
    "            if not (0 in u and 1 in u and len(u)==2): #if not binary\n",
    "                not_bi.append(i)\n",
    "        return not_bi\n",
    "    \n",
    "    def reg(x_train, y_train):\n",
    "           \n",
    "        model = LogisticRegression(penalty='l2',class_weight='balanced',solver='sag',n_jobs=-1)\n",
    "        \n",
    "        \"\"\"\n",
    "        Why we need standardize?\n",
    "        \n",
    "        Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features \n",
    "        with approximately the same scale. You can preprocess the data with \n",
    "        a scaler from sklearn.preprocessing.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = model.fit(x_train, y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def ModelValuation(x_test,y_test,model):\n",
    "        \n",
    "        probs = model.predict_proba(x_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, probs[:, 1])\n",
    "        \n",
    "        plt.figure(1)\n",
    "        plt.plot(fpr, tpr, label='LogisticRegression')\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.title('ROC curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Area Under the Curve (AUC) from prediction score is %f\" % metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "    \n",
    "        return None  \n",
    "    \n",
    "    def y_pred(x_test,threshold=0.5):\n",
    "        \n",
    "        if threshold == 0.5:\n",
    "            y_predicted = model.predict(x_test)\n",
    "        else:\n",
    "            probs = model.predict_proba(x_test)\n",
    "            y_predicted = np.array(probs[:,1] >= threshold).astype(int)\n",
    "        \n",
    "        return y_predicted    \n",
    "    \n",
    "    def GetScores(y_test,y_predicted):\n",
    "        #G means score \n",
    "        CM = metrics.confusion_matrix(y_test, y_predicted)\n",
    "        TN = CM[0,0]\n",
    "        FN = CM[1,0]\n",
    "        TP = CM[1,1]\n",
    "        FP = CM[0,1]\n",
    "        \n",
    "        sensitivity = float(TP)/float(TP+FN)\n",
    "        specificity = float(TN)/float(TN+FP)\n",
    "        G = np.sqrt(sensitivity*specificity)\n",
    "        print(\"G score is %f\" % G)\n",
    "        print(\"Specificity is %f\" % specificity)\n",
    "        \n",
    "        # Generate and display different evaluation metrics\n",
    "        print(\"Mean accuracy score is %f\" % metrics.accuracy_score(y_test, y_predicted))\n",
    "          \n",
    "        print(\"Confusion Marix\")\n",
    "        print(CM)\n",
    "        \n",
    "        return specificity , G\n",
    "        \n",
    "    # Convenience function to plot confusion matrix\n",
    "    def confusion(y_test,y_predicted,title):\n",
    "        \n",
    "        # Define names for the three Iris types\n",
    "        names = ['Default', 'Not Default']\n",
    "    \n",
    "        # Make a 2D histogram from the test and result arrays\n",
    "        pts, xe, ye = np.histogram2d(y_test, y_predicted, bins=2)\n",
    "    \n",
    "        # For simplicity we create a new DataFrame\n",
    "        pd_pts = pd.DataFrame(pts.astype(int), index=names, columns=names )\n",
    "        \n",
    "        # Display heatmap and add decorations\n",
    "        hm = sns.heatmap(pd_pts, annot=True, fmt=\"d\")\n",
    "        hm.axes.set_title(title)\n",
    "        \n",
    "        return None\n",
    "            \n",
    "    def find_threshold(x_test,y_test):\n",
    "    \n",
    "        probs = model.predict_proba(x_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, probs[:, 1])\n",
    "        \n",
    "        sensitivity = tpr\n",
    "        specificity = 1 - fpr\n",
    "        G = np.sqrt(sensitivity*specificity)\n",
    "        \n",
    "        plt.figure(2)\n",
    "        plt.plot(thresholds,G)\n",
    "        plt.xlabel('Thresholds')\n",
    "        plt.ylabel('G-Scores')\n",
    "        plt.title('G-Scores with different thresholds')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        print(\"The highest G score is %f with threshold at %f\" % (np.amax(G),thresholds[np.argmax(G)]) )\n",
    "        \n",
    "        return thresholds[np.argmax(G)]\n",
    "    # this is just testing, we add weight so we don't need to adjust threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Class Logistic Regression(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% logistic regression\n",
    "class Multi_log_reg():\n",
    "    # Evaluate the model by splitting into train and test sets\n",
    "    def split(x,y,rand=0):\n",
    "        \n",
    "        y = np.ravel(y)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25,random_state=rand)\n",
    "        \n",
    "        return x_train, x_test, y_train, y_test \n",
    "    #we need to add validation dataset here\n",
    "    \n",
    "    # Find binary column method one\n",
    "    def bool_cols(df,isbool=True):\n",
    "        bool_cols=[]\n",
    "        for col in df:\n",
    "            if isbool==True:\n",
    "                if df[col].dropna().value_counts().index.isin([0,1]).all():\n",
    "                    bool_cols.append(col)\n",
    "            else:\n",
    "                if not df[col].dropna().value_counts().index.isin([0,1]).all():\n",
    "                    bool_cols.append(col)\n",
    "        return bool_cols\n",
    "    # this above step is to facilitate normalization later\n",
    "    # method two\n",
    "    def not_bi(x):\n",
    "        not_bi=[]\n",
    "        for i in list(x):\n",
    "            u=x[i].unique()\n",
    "            if not (0 in u and 1 in u and len(u)==2): #if not binary\n",
    "                not_bi.append(i)\n",
    "        return not_bi\n",
    "    \n",
    "    def reg(x_train, y_train):\n",
    "           \n",
    "        model = LogisticRegression(penalty='l2',class_weight='balanced',solver='sag',n_jobs=-1,multi_class='multinomial')\n",
    "        \n",
    "        \"\"\"\n",
    "        Why we need standardize?\n",
    "        \n",
    "        Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features \n",
    "        with approximately the same scale. You can preprocess the data with \n",
    "        a scaler from sklearn.preprocessing.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = model.fit(x_train, y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def score(X,y,model):\n",
    "        return model.score(X, y, sample_weight=None)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Logistic Regression with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Lasso logistic regression\n",
    "class L1_log_reg():\n",
    "    # Evaluate the model by splitting into train and test sets\n",
    "    def split(x,y,rand=0):\n",
    "        \n",
    "        y = np.ravel(y)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25,random_state=rand)\n",
    "        \n",
    "        return x_train, x_test, y_train, y_test \n",
    "    #we need to add validation dataset here\n",
    "    \n",
    "    # Find binary column method one\n",
    "    def bool_cols(df,isbool=True):\n",
    "        bool_cols=[]\n",
    "        for col in df:\n",
    "            if isbool==True:\n",
    "                if df[col].dropna().value_counts().index.isin([0,1]).all():\n",
    "                    bool_cols.append(col)\n",
    "            else:\n",
    "                if not df[col].dropna().value_counts().index.isin([0,1]).all():\n",
    "                    bool_cols.append(col)\n",
    "        return bool_cols\n",
    "    # this above step is to facilitate normalization later\n",
    "    # method two\n",
    "    def not_bi(x):\n",
    "        not_bi=[]\n",
    "        for i in list(x):\n",
    "            u=x[i].unique()\n",
    "            if not (0 in u and 1 in u and len(u)==2): #if not binary\n",
    "                not_bi.append(i)\n",
    "        return not_bi\n",
    "    \n",
    "    def reg(x_train, y_train):\n",
    "           \n",
    "        model = LogisticRegression(penalty='L1',class_weight='balanced',solver='saga',n_jobs=-1)\n",
    "        \n",
    "        \"\"\"\n",
    "        Why we need standardize?\n",
    "        \n",
    "        Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features \n",
    "        with approximately the same scale. You can preprocess the data with \n",
    "        a scaler from sklearn.preprocessing.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = model.fit(x_train, y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def ModelValuation(x_test,y_test,model):\n",
    "        \n",
    "        probs = model.predict_proba(x_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, probs[:, 1])\n",
    "        \n",
    "        plt.figure(1)\n",
    "        plt.plot(fpr, tpr, label='LogisticRegression')\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.title('ROC curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Area Under the Curve (AUC) from prediction score is %f\" % metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "    \n",
    "        return None  \n",
    "    \n",
    "    def y_pred(x_test,threshold=0.5):\n",
    "        \n",
    "        if threshold == 0.5:\n",
    "            y_predicted = model.predict(x_test)\n",
    "        else:\n",
    "            probs = model.predict_proba(x_test)\n",
    "            y_predicted = np.array(probs[:,1] >= threshold).astype(int)\n",
    "        \n",
    "        return y_predicted    \n",
    "    \n",
    "    def GetScores(y_test,y_predicted):\n",
    "        #G means score \n",
    "        CM = metrics.confusion_matrix(y_test, y_predicted)\n",
    "        TN = CM[0,0]\n",
    "        FN = CM[1,0]\n",
    "        TP = CM[1,1]\n",
    "        FP = CM[0,1]\n",
    "        \n",
    "        sensitivity = float(TP)/float(TP+FN)\n",
    "        specificity = float(TN)/float(TN+FP)\n",
    "        G = np.sqrt(sensitivity*specificity)\n",
    "        print(\"G score is %f\" % G)\n",
    "        print(\"Specificity is %f\" % specificity)\n",
    "        \n",
    "        # Generate and display different evaluation metrics\n",
    "        print(\"Mean accuracy score is %f\" % metrics.accuracy_score(y_test, y_predicted))\n",
    "          \n",
    "        print(\"Confusion Marix\")\n",
    "        print(CM)\n",
    "        \n",
    "        return specificity , G\n",
    "        \n",
    "    # Convenience function to plot confusion matrix\n",
    "    def confusion(y_test,y_predicted,title):\n",
    "        \n",
    "        # Define names for the three Iris types\n",
    "        names = ['Default', 'Not Default']\n",
    "    \n",
    "        # Make a 2D histogram from the test and result arrays\n",
    "        pts, xe, ye = np.histogram2d(y_test, y_predicted, bins=2)\n",
    "    \n",
    "        # For simplicity we create a new DataFrame\n",
    "        pd_pts = pd.DataFrame(pts.astype(int), index=names, columns=names )\n",
    "        \n",
    "        # Display heatmap and add decorations\n",
    "        hm = sns.heatmap(pd_pts, annot=True, fmt=\"d\")\n",
    "        hm.axes.set_title(title)\n",
    "        \n",
    "        return None\n",
    "            \n",
    "    def find_threshold(x_test,y_test):\n",
    "    \n",
    "        probs = model.predict_proba(x_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, probs[:, 1])\n",
    "        \n",
    "        sensitivity = tpr\n",
    "        specificity = 1 - fpr\n",
    "        G = np.sqrt(sensitivity*specificity)\n",
    "        \n",
    "        plt.figure(2)\n",
    "        plt.plot(thresholds,G)\n",
    "        plt.xlabel('Thresholds')\n",
    "        plt.ylabel('G-Scores')\n",
    "        plt.title('G-Scores with different thresholds')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        print(\"The highest G score is %f with threshold at %f\" % (np.amax(G),thresholds[np.argmax(G)]) )\n",
    "        \n",
    "        return thresholds[np.argmax(G)]\n",
    "    # this is just testing, we add weight so we don't need to adjust threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Binary logistic Regression(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrMBJwczMCpwUzMyswEnBzMwK/j+3+uG5o0ZLagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2249701e358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the Curve (AUC) from prediction score is 0.998210\n",
      "G score is 0.986635\n",
      "Specificity is 0.975283\n",
      "Mean accuracy score is 0.992387\n",
      "Confusion Marix\n",
      "[[ 50229   1273]\n",
      " [   289 153385]]\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "x_train, x_test, y_train, y_test = log_reg.split(x,y,rand=None)\n",
    "# Normalize\n",
    "not_bi = log_reg.not_bi(x)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train[not_bi]) \n",
    "\n",
    "x_train_scaled=x_train\n",
    "x_test_scaled=x_test\n",
    "\n",
    "x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "model = log_reg.reg(x_train_scaled,y_train)\n",
    "# Evaluate model\n",
    "log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Multi-Class(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.898970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train_multi, x_test_multi, y_train_multi, y_test_multi = Multi_log_reg.split(x_multi,y_multi,rand=None)\n",
    "# Normalize\n",
    "not_bi = Multi_log_reg.not_bi(x_multi)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train_multi[not_bi]) \n",
    "\n",
    "x_train_scaled_multi=x_train_multi\n",
    "x_test_scaled_multi=x_test_multi\n",
    "\n",
    "x_train_scaled_multi[not_bi] = scaler.transform(x_train_multi[not_bi])\n",
    "x_test_scaled_multi[not_bi]  = scaler.transform(x_test_multi[not_bi])\n",
    "\n",
    "# Fit model\n",
    "model_multi = Multi_log_reg.reg(x_train_scaled_multi,y_train_multi)\n",
    "# Evaluate model\n",
    "print(\"Mean accuracy score is %f\" % model_multi.score(x_test_scaled_multi,y_test_multi,sample_weight=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the mean accuracy score for every class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy for fully paid 0.9981941015980252\n",
      "mean accuracy for Grace Period 0.5038397328881469\n",
      "mean accuracy for Late 0.5545619673047366\n",
      "mean accuracy for Default 0.6159818907603933\n"
     ]
    }
   ],
   "source": [
    "y_predicted_multi = model_multi.predict(x_test_multi)\n",
    "cnt_0=0\n",
    "cnt_0_predicted=0\n",
    "cnt_1=0\n",
    "cnt_1_predicted=0\n",
    "cnt_2=0\n",
    "cnt_2_predicted=0\n",
    "cnt_3=0\n",
    "cnt_3_predicted=0\n",
    "for x in range(len(y_predicted_multi)):\n",
    "    if y_test_multi[x]==0:\n",
    "        cnt_0+=1\n",
    "    if y_test_multi[x]==0 and y_predicted_multi[x]==0:\n",
    "        cnt_0_predicted+=1 \n",
    "    if y_test_multi[x]==1:\n",
    "        cnt_1+=1\n",
    "    if y_test_multi[x]==1 and y_predicted_multi[x]==1:\n",
    "        cnt_1_predicted+=1 \n",
    "    if y_test_multi[x]==2:\n",
    "        cnt_2+=1\n",
    "    if y_test_multi[x]==2 and y_predicted_multi[x]==2:\n",
    "        cnt_2_predicted+=1 \n",
    "    if y_test_multi[x]==3:\n",
    "        cnt_3+=1\n",
    "    if y_test_multi[x]==3 and y_predicted_multi[x]==3:\n",
    "        cnt_3_predicted+=1 \n",
    "print(\"mean accuracy for fully paid\", cnt_0_predicted/cnt_0)\n",
    "print(\"mean accuracy for Grace Period\", cnt_1_predicted/cnt_1)\n",
    "print(\"mean accuracy for Late\", cnt_2_predicted/cnt_2)\n",
    "print(\"mean accuracy for Default\", cnt_3_predicted/cnt_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Binary Logistic Regression with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEWCAYAAACAOivfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABAmAgBhAyo2Cpc0AydZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2249932ce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the Curve (AUC) from prediction score is 0.500720\n",
      "G score is 0.912628\n",
      "Specificity is 0.832965\n",
      "Mean accuracy score is 0.958338\n",
      "Confusion Marix\n",
      "[[ 42557   8534]\n",
      " [    14 154071]]\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "x_train_L1, x_test_L1, y_train_L1, y_test_L1 = L1_log_reg.split(x,y,rand=None)\n",
    "# Normalize\n",
    "not_bi = log_reg.not_bi(x)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train[not_bi]) \n",
    "\n",
    "x_train_scaled_L1=x_train_L1\n",
    "x_test_scaled_L1=x_test_L1\n",
    "\n",
    "x_train_scaled_L1[not_bi] = scaler.transform(x_train_L1[not_bi])\n",
    "x_test_scaled_L1[not_bi]  = scaler.transform(x_test_L1[not_bi])\n",
    "\n",
    "# Fit model\n",
    "model_L1 = L1_log_reg.reg(x_train_scaled_L1,y_train_L1)\n",
    "# Evaluate model\n",
    "L1_log_reg.ModelValuation(x_test_scaled_L1,y_test,model_L1)\n",
    "y_predicted_L1 = L1_log_reg.y_pred(x_test_scaled_L1,threshold=0.5)\n",
    "spec , G = L1_log_reg.GetScores(y_test_L1,y_predicted_L1)\n",
    "L1_log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
