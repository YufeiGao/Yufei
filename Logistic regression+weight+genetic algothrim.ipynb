{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data process(Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class data_proc():\n",
    "    \n",
    "    def process_zip():\n",
    "        #dealing with zipcode\n",
    "        zip_data=pd.read_csv('ZIP.csv')\n",
    "        zip_data['Zip']=zip_data['Zip'].astype(str)\n",
    "        for i in range(len(zip_data['Zip'])):\n",
    "            if len(zip_data['Zip'][i])==4:\n",
    "                zip_data['Zip'][i]='0'+zip_data['Zip'][i]\n",
    "        zip_data['Zip']=[zip_data['Zip'][i][0:3] for i in range(len(zip_data))] \n",
    "        zip_data.iloc[:,-3:]=zip_data[['Median','Mean','Pop']].apply(lambda x: x.str.replace(',',''))\n",
    "        for i in range(1,4):\n",
    "            zip_data.iloc[:,-i]=pd.to_numeric(zip_data.iloc[:,-i],errors='coerce')\n",
    "        zip_data['weight']=zip_data['Pop']/zip_data.groupby('Zip')['Pop'].transform(sum)\n",
    "        zip_data['new_mean']=zip_data['Mean']*zip_data['weight']\n",
    "        zip_data['new_median']=zip_data['Median']*zip_data['weight']\n",
    "        zip_new=pd.DataFrame()\n",
    "        zip_new=zip_data.groupby('Zip')['new_mean','new_median'].sum()\n",
    "        return zip_new\n",
    "        \n",
    "    def readcsv():\n",
    "        LARGE_FILE = \"loan_data_no_current_converted.csv\"\n",
    "        CHUNKSIZE = 100000 # processing 100,000 rows at a time\n",
    "        reader = pd.read_csv(LARGE_FILE, chunksize=CHUNKSIZE, low_memory=False)\n",
    "        frames = []\n",
    "        for df in reader:\n",
    "            frames.append(df)\n",
    "        loan_data = pd.concat(frames)\n",
    "        return loan_data   \n",
    "    def cleaning(df,zip_new,keep_desc=True,categorical_to_binary=True):\n",
    "        df=df.dropna(axis=0,how='all')\n",
    "        drop_list=['installment','term','emp_title','title','earliest_cr_line','desc','issue_d','id','member_id','url','grade','sub_grade',\n",
    "                   'int_rate','avg_cur_bal','addr_state','funded_amnt','funded_amnt_inv','collection_recovery_fee',\n",
    "                   'collections_12_mths_ex_med','mths_since_last_major_derog','next_pymnt_d','recoveries','total_pymnt',\n",
    "                   'total_pymnt_inv','total_rec_int','issue_d',' last_credit_pull_d','last_pymnt_d','last_credit_pull_d',\n",
    "                  'total_rec_prncp','settlement_status','hardship_loan_status','hardship_status','debt_settlement_flag',\n",
    "                   'verification_status','total_rec_late_fee']\n",
    "        df.drop(drop_list,inplace=True,axis=1,errors='ignore')\n",
    "        #deal with percentage mark\n",
    "        df['revol_util']=df['revol_util'].replace('%','',regex=True).astype('float')/100\n",
    "        #merge zipcode with census data\n",
    "        df['zip_code']=df['zip_code'].apply(lambda x: x[:3])\n",
    "        df=df.join(zip_new,on='zip_code')\n",
    "        df.drop('zip_code',inplace=True,axis=1)\n",
    "        #drop the observation that was missing for ALL field\n",
    "        df=df.dropna(axis=0,how='all')\n",
    "        #drop the features for which greater than 10% of the loans were missing data for\n",
    "        num_rows=df.count(axis=0)\n",
    "        df=df.iloc[:,(num_rows>=0.9*len(df)).tolist()]\n",
    "        #drop the observation that was missing for any field\n",
    "        df=df.dropna(axis=0,how='any')\n",
    "        #label the dataset to create y\n",
    "        #0:fully paid, does not meet policy:fully paid\n",
    "        #1:Does not meet the credit policy. Status:Charged Off\",default,charge of\n",
    "        df=df[(True-df['loan_status'].isin([4]))] \n",
    "        df=df[(True-df['loan_status'].isin([5]))]\n",
    "        df=df[(True-df['loan_status'].isin([6]))] \n",
    "        #label the dataset to create y\n",
    "        y=df['loan_status'].replace(1,0)\n",
    "        y=y.replace(2,0)\n",
    "        y=y.replace(3,1)\n",
    "        y=y.replace(7,1)\n",
    "        y=y.replace(8,1)\n",
    "        df=df.drop(['loan_status'],axis=1) \n",
    "        return df,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run data_proc class to get Binary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:183: UserWarning: evaluating in Python space because the '-' operator is not supported by numexpr for the bool dtype, use '^' instead\n",
      "  unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "zipdata = data_proc.process_zip()\n",
    "df = data_proc.readcsv()\n",
    "x,y = data_proc.cleaning(df,zipdata,keep_desc=False,categorical_to_binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Logistic Regression(Ridge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% Binary logistic regression\n",
    "class log_reg():\n",
    "    # Evaluate the model by splitting into train and test sets\n",
    "    def split(x,y,rand=0):\n",
    "        \n",
    "        y = np.ravel(y)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25,random_state=rand)\n",
    "        \n",
    "        return x_train, x_test, y_train, y_test \n",
    "    #we need to add validation dataset here\n",
    "    \n",
    "    # Find binary column method one\n",
    "    def bool_cols(df,isbool=True):\n",
    "        bool_cols=[]\n",
    "        for col in df:\n",
    "            if isbool==True:\n",
    "                if df[col].dropna().value_counts().index.isin([0,1]).all():\n",
    "                    bool_cols.append(col)\n",
    "            else:\n",
    "                if not df[col].dropna().value_counts().index.isin([0,1]).all():\n",
    "                    bool_cols.append(col)\n",
    "        return bool_cols\n",
    "    # this above step is to facilitate normalization later\n",
    "    # method two\n",
    "    def not_bi(x):\n",
    "        not_bi=[]\n",
    "        for i in list(x):\n",
    "            u=x[i].unique()\n",
    "            if not (0 in u and 1 in u and len(u)==2): #if not binary\n",
    "                not_bi.append(i)\n",
    "        return not_bi\n",
    "    \n",
    "    def reg(x_train, y_train):\n",
    "           \n",
    "        model = LogisticRegression(penalty='l2',class_weight='balanced',solver='sag',n_jobs=-1)\n",
    "        \n",
    "        \"\"\"\n",
    "        Why we need standardize?\n",
    "        \n",
    "        Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features \n",
    "        with approximately the same scale. You can preprocess the data with \n",
    "        a scaler from sklearn.preprocessing.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = model.fit(x_train, y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def ModelValuation(x_test,y_test,model):\n",
    "        \n",
    "        probs = model.predict_proba(x_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, probs[:, 1])\n",
    "        \n",
    "        plt.figure(1)\n",
    "        plt.plot(fpr, tpr, label='LogisticRegression')\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.title('ROC curve')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Area Under the Curve (AUC) from prediction score is %f\" % metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "    \n",
    "        return None  \n",
    "    \n",
    "    def y_pred(x_test,threshold=0.5):\n",
    "        \n",
    "        if threshold == 0.5:\n",
    "            y_predicted = model.predict(x_test)\n",
    "        else:\n",
    "            probs = model.predict_proba(x_test)\n",
    "            y_predicted = np.array(probs[:,1] >= threshold).astype(int)\n",
    "        \n",
    "        return y_predicted    \n",
    "    \n",
    "    def GetScores(y_test,y_predicted):\n",
    "        #G means score \n",
    "        CM = metrics.confusion_matrix(y_test, y_predicted)\n",
    "        TN = CM[0,0]\n",
    "        FN = CM[1,0]\n",
    "        TP = CM[1,1]\n",
    "        FP = CM[0,1]\n",
    "        \n",
    "        sensitivity = float(TP)/float(TP+FN)\n",
    "        specificity = float(TN)/float(TN+FP)\n",
    "        G = np.sqrt(sensitivity*specificity)\n",
    "        print(\"G score is %f\" % G)\n",
    "        print(\"Specificity is %f\" % specificity)\n",
    "        \n",
    "        # Generate and display different evaluation metrics\n",
    "        print(\"Mean accuracy score is %f\" % metrics.accuracy_score(y_test, y_predicted))\n",
    "          \n",
    "        print(\"Confusion Marix\")\n",
    "        print(CM)\n",
    "        \n",
    "        return specificity , G\n",
    "        \n",
    "    # Convenience function to plot confusion matrix\n",
    "    def confusion(y_test,y_predicted,title):\n",
    "        \n",
    "        # Define names for the three Iris types\n",
    "        names = ['Default', 'Not Default']\n",
    "    \n",
    "        # Make a 2D histogram from the test and result arrays\n",
    "        pts, xe, ye = np.histogram2d(y_test, y_predicted, bins=2)\n",
    "    \n",
    "        # For simplicity we create a new DataFrame\n",
    "        pd_pts = pd.DataFrame(pts.astype(int), index=names, columns=names )\n",
    "        \n",
    "        # Display heatmap and add decorations\n",
    "        hm = sns.heatmap(pd_pts, annot=True, fmt=\"d\")\n",
    "        hm.axes.set_title(title)\n",
    "        \n",
    "        return None\n",
    "            \n",
    "    def find_threshold(x_test,y_test):\n",
    "    \n",
    "        probs = model.predict_proba(x_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, probs[:, 1])\n",
    "        \n",
    "        sensitivity = tpr\n",
    "        specificity = 1 - fpr\n",
    "        G = np.sqrt(sensitivity*specificity)\n",
    "        \n",
    "        plt.figure(2)\n",
    "        plt.plot(thresholds,G)\n",
    "        plt.xlabel('Thresholds')\n",
    "        plt.ylabel('G-Scores')\n",
    "        plt.title('G-Scores with different thresholds')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        print(\"The highest G score is %f with threshold at %f\" % (np.amax(G),thresholds[np.argmax(G)]) )\n",
    "        \n",
    "        return thresholds[np.argmax(G)]\n",
    "    # this is just testing, we add weight so we don't need to adjust threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Binary logistic Regression(Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Xianzhe Xu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noKQgIiIVlBRERKTC/wfxbqqMI/DNSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bf2a76e898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under the Curve (AUC) from prediction score is 0.931268\n",
      "G score is 0.868532\n",
      "Specificity is 0.781124\n",
      "Mean accuracy score is 0.820295\n",
      "Confusion Marix\n",
      "[[118780  33283]\n",
      " [  1404  39555]]\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "x_train, x_test, y_train, y_test = log_reg.split(x,y,rand=None)\n",
    "# Normalize\n",
    "not_bi = log_reg.not_bi(x)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train[not_bi]) \n",
    "\n",
    "x_train_scaled=x_train\n",
    "x_test_scaled=x_test\n",
    "\n",
    "x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "model = log_reg.reg(x_train_scaled,y_train)\n",
    "# Evaluate model\n",
    "log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the mean accuracy score for every class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy for fully paid 0.7811236132392495\n",
      "mean accuracy for Default 0.965721819380356\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(x_test)\n",
    "cnt_0=0\n",
    "cnt_0_predicted=0\n",
    "cnt_1=0\n",
    "cnt_1_predicted=0\n",
    "for x in range(len(y_predicted)):\n",
    "    if y_test[x]==0:\n",
    "        cnt_0+=1\n",
    "    if y_test[x]==0 and y_predicted[x]==0:\n",
    "        cnt_0_predicted+=1 \n",
    "    if y_test[x]==1:\n",
    "        cnt_1+=1\n",
    "    if y_test[x]==1 and y_predicted[x]==1:\n",
    "        cnt_1_predicted+=1 \n",
    "print(\"mean accuracy for fully paid\", cnt_0_predicted/cnt_0)\n",
    "print(\"mean accuracy for Default\", cnt_1_predicted/cnt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loan_amnt',\n",
       " 'emp_length',\n",
       " 'home_ownership',\n",
       " 'annual_inc',\n",
       " 'pymnt_plan',\n",
       " 'purpose',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'inq_last_6mths',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'initial_list_status',\n",
       " 'out_prncp',\n",
       " 'out_prncp_inv',\n",
       " 'last_pymnt_amnt',\n",
       " 'policy_code',\n",
       " 'application_type',\n",
       " 'acc_now_delinq',\n",
       " 'tot_coll_amt',\n",
       " 'tot_cur_bal',\n",
       " 'total_rev_hi_lim',\n",
       " 'acc_open_past_24mths',\n",
       " 'bc_open_to_buy',\n",
       " 'bc_util',\n",
       " 'chargeoff_within_12_mths',\n",
       " 'delinq_amnt',\n",
       " 'mo_sin_old_rev_tl_op',\n",
       " 'mo_sin_rcnt_rev_tl_op',\n",
       " 'mo_sin_rcnt_tl',\n",
       " 'mort_acc',\n",
       " 'mths_since_recent_bc',\n",
       " 'num_accts_ever_120_pd',\n",
       " 'num_actv_bc_tl',\n",
       " 'num_actv_rev_tl',\n",
       " 'num_bc_sats',\n",
       " 'num_bc_tl',\n",
       " 'num_il_tl',\n",
       " 'num_op_rev_tl',\n",
       " 'num_rev_accts',\n",
       " 'num_rev_tl_bal_gt_0',\n",
       " 'num_sats',\n",
       " 'num_tl_30dpd',\n",
       " 'num_tl_90g_dpd_24m',\n",
       " 'num_tl_op_past_12m',\n",
       " 'pct_tl_nvr_dlq',\n",
       " 'percent_bc_gt_75',\n",
       " 'pub_rec_bankruptcies',\n",
       " 'tax_liens',\n",
       " 'tot_hi_cred_lim',\n",
       " 'total_bal_ex_mort',\n",
       " 'total_bc_limit',\n",
       " 'total_il_high_credit_limit',\n",
       " 'hardship_flag',\n",
       " 'hardship_type',\n",
       " 'hardship_reason',\n",
       " 'disbursement_method',\n",
       " 'new_mean',\n",
       " 'new_median']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features=[]\n",
    "for key, value in x_train_scaled.iteritems():\n",
    "    features.append(key)\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficient=[]\n",
    "feature_coef=model.coef_\n",
    "for x in feature_coef:\n",
    "    for y in x:\n",
    "        coefficient.append(y)\n",
    "weight=zip(features,coefficient)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('loan_amnt', 0.95128207471162107), ('total_bal_ex_mort', 0.31977614766316848), ('dti', 0.30717652410352736), ('acc_open_past_24mths', 0.29148903268001325), ('initial_list_status', 0.18680750146172492), ('percent_bc_gt_75', 0.17789617533049809), ('num_bc_sats', 0.14808388800458697), ('num_tl_op_past_12m', 0.13656290472004876), ('delinq_2yrs', 0.11828028469510475), ('purpose', 0.11608631189702585), ('hardship_reason', 0.085809991017707532), ('out_prncp_inv', 0.084186082907108634), ('out_prncp', 0.084170587716691322), ('inq_last_6mths', 0.081806312064737235), ('pub_rec', 0.073011994469276267), ('new_median', 0.061688258054992444), ('num_accts_ever_120_pd', 0.057616095514475996), ('revol_util', 0.056659509355668151), ('tot_cur_bal', 0.054363828404613027), ('disbursement_method', 0.036536101520646382), ('application_type', 0.026227242926594539), ('num_rev_tl_bal_gt_0', 0.024169700076661131), ('acc_now_delinq', 0.022626302516030965), ('pub_rec_bankruptcies', 0.01936261552115531), ('mo_sin_rcnt_rev_tl_op', 0.016664806380642522), ('chargeoff_within_12_mths', 0.012992686226693332), ('num_op_rev_tl', 0.011716103250291881), ('hardship_type', 0.0093958546417571877), ('delinq_amnt', 0.0087686316186182476), ('num_rev_accts', 0.007718141022277792), ('pct_tl_nvr_dlq', 0.0026300321553876316), ('num_tl_30dpd', 0.001883070311929421), ('hardship_flag', 0.0), ('policy_code', 0.0), ('pymnt_plan', 0.0), ('tot_coll_amt', -0.0015108838063587495), ('num_actv_bc_tl', -0.013067127882715883), ('num_actv_rev_tl', -0.019982185239988286), ('bc_open_to_buy', -0.020062998691228788), ('num_il_tl', -0.025560671446168068), ('annual_inc', -0.027874631714582872), ('tax_liens', -0.032267074238442321), ('mo_sin_rcnt_tl', -0.033729141953561574), ('num_tl_90g_dpd_24m', -0.03516155285277444), ('mort_acc', -0.038775662051072315), ('open_acc', -0.039796640012398111), ('num_sats', -0.046070580876285329), ('total_rev_hi_lim', -0.046255552686682452), ('emp_length', -0.056842208448558675), ('mo_sin_old_rev_tl_op', -0.062579490161025847), ('total_acc', -0.066697347142066876), ('revol_bal', -0.071393740020225985), ('home_ownership', -0.072140935284877875), ('mths_since_recent_bc', -0.073585507905660971), ('new_mean', -0.095006508886105429), ('bc_util', -0.10307911325563411), ('num_bc_tl', -0.1251247517065954), ('tot_hi_cred_lim', -0.16860049066271954), ('total_bc_limit', -0.20625699104528311), ('total_il_high_credit_limit', -0.32426141531147062), ('last_pymnt_amnt', -6.168244846435786)]\n"
     ]
    }
   ],
   "source": [
    "weight=tuple(weight)\n",
    "print (sorted(weight, key=lambda t: (-t[1], t[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('loan_amnt', 0.95128207471162107), ('total_bal_ex_mort', 0.31977614766316848), ('dti', 0.30717652410352736), ('acc_open_past_24mths', 0.29148903268001325), ('initial_list_status', 0.18680750146172492), ('percent_bc_gt_75', 0.17789617533049809), ('num_bc_sats', 0.14808388800458697), ('num_tl_op_past_12m', 0.13656290472004876), ('delinq_2yrs', 0.11828028469510475), ('purpose', 0.11608631189702585)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(weight, key=lambda t: (-t[1], t[0]))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBRegressor is not available and will not be used by TPOT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -0.083838768565413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: -0.08064426478439243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: -0.08064426478439243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: -0.07324939153201887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: -0.07324939153201887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: DecisionTreeRegressor(DecisionTreeRegressor(RidgeCV(input_matrix), max_depth=3, min_samples_leaf=18, min_samples_split=3), max_depth=7, min_samples_leaf=7, min_samples_split=2)\n",
      "-0.0734595202825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2)\n",
    "tpot.fit(x_train_scaled, y_train)\n",
    "print(tpot.score(x_test_scaled, y_test))\n",
    "tpot.export('tpot_boston_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpot_pred = tpot.predict(x_test_scaled)\n",
    "sub1 = pd.DataFrame(data=tpot_pred)\n",
    "sub1.to_csv('tpot1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(len(tpot_pred)):\n",
    "    if tpot_pred[x]<0.5:\n",
    "        tpot_pred[x]=0\n",
    "    else:\n",
    "        tpot_pred[x]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy for fully paid 0.9267935000624741\n",
      "mean accuracy for Default 0.7398373983739838\n",
      "total mean accuray 0.8871216752494534\n"
     ]
    }
   ],
   "source": [
    "cnt_0=0\n",
    "cnt_0_predicted=0\n",
    "cnt_1=0\n",
    "cnt_1_predicted=0\n",
    "for x in range(len(y_predicted)):\n",
    "    if y_test[x]==0:\n",
    "        cnt_0+=1\n",
    "    if y_test[x]==0 and tpot_pred[x]==0:\n",
    "        cnt_0_predicted+=1 \n",
    "    if y_test[x]==1:\n",
    "        cnt_1+=1\n",
    "    if y_test[x]==1 and tpot_pred[x]==1:\n",
    "        cnt_1_predicted+=1 \n",
    "print(\"mean accuracy for fully paid\", cnt_0_predicted/cnt_0)\n",
    "print(\"mean accuracy for Default\", cnt_1_predicted/cnt_1)\n",
    "print(\"total mean accuray\",( cnt_0_predicted+cnt_1_predicted)/(cnt_0+cnt_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
