{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class data_proc():\n",
    "    def process_zip():\n",
    "        #dealing with zipcode\n",
    "        zip_data=pd.read_csv('ZIP.csv')\n",
    "        zip_data['Zip']=zip_data['Zip'].astype(str)\n",
    "        for i in range(len(zip_data['Zip'])):\n",
    "            if len(zip_data['Zip'][i])==4:\n",
    "                zip_data['Zip'][i]='0'+zip_data['Zip'][i]\n",
    "        zip_data['Zip']=[zip_data['Zip'][i][0:3] for i in range(len(zip_data))] \n",
    "        zip_data.iloc[:,-3:]=zip_data[['Median','Mean','Pop']].apply(lambda x: x.str.replace(',',''))\n",
    "        for i in range(1,4):\n",
    "            zip_data.iloc[:,-i]=pd.to_numeric(zip_data.iloc[:,-i],errors='coerce')\n",
    "        zip_data['weight']=zip_data['Pop']/zip_data.groupby('Zip')['Pop'].transform(sum)\n",
    "        zip_data['new_mean']=zip_data['Mean']*zip_data['weight']\n",
    "        zip_data['new_median']=zip_data['Median']*zip_data['weight']\n",
    "        zip_new=pd.DataFrame()\n",
    "        zip_new=zip_data.groupby('Zip')['new_mean','new_median'].sum()\n",
    "        return zip_new\n",
    "        \n",
    "    def readcsv():\n",
    "        LARGE_FILE = \"C:\\Users\\Administrator\\Desktop\\practicum_regression\\loan_data_no_current_converted.csv\"\n",
    "        CHUNKSIZE = 100000 # processing 100,000 rows at a time\n",
    "        reader = pd.read_csv(LARGE_FILE, chunksize=CHUNKSIZE, low_memory=False)\n",
    "        frames = []\n",
    "        for df in reader:\n",
    "            frames.append(df)\n",
    "        loan_data = pd.concat(frames)\n",
    "        return loan_data    \n",
    "        \n",
    "    def cleaning(df,zip_new,keep_desc=True,categorical_to_binary=True):\n",
    "        #drop the observation that was missing for ALL field\n",
    "        df=df.dropna(axis=0,how='all')\n",
    "        #drop the meaningless features\n",
    "        drop_list=['emp_title','title','earliest_cr_line','desc','issue_d','id','member_id','url','grade','sub_grade',\n",
    "                   'int_rate','avg_cur_bal','addr_state','funded_amnt','funded_amnt_inv','collection_recovery_fee',\n",
    "                   'collections_12_mths_ex_med','mths_since_last_major_derog','next_pymnt_d','recoveries','total_pymnt',\n",
    "                   'total_pymnt_inv','total_rec_int','issue_d',' last_credit_pull_d','last_pymnt_d','last_credit_pull_d']\n",
    "        df.drop(drop_list,inplace=True,axis=1,errors='ignore')\n",
    "        \n",
    "        #deal with percentage mark\n",
    "        df['revol_util']=df['revol_util'].replace('%','',regex=True).astype('float')/100\n",
    "        \n",
    "        #dealing with categorical features\n",
    "        if categorical_to_binary==True:\n",
    "            categorical_features=['addr_state','application_type','emp_length','grade','home_ownership','initial_list_status','pymnt_plan','sub_grade','term','verification_status']\n",
    "            for i in categorical_features:\n",
    "                if i in list(df):\n",
    "                    df[i]=df[i].astype('category')\n",
    "                    df=pd.get_dummies(df,columns={i},drop_first=True)\n",
    "        \n",
    "        #merge zipcode with census data\n",
    "        df['zip_code']=df['zip_code'].apply(lambda x: x[:3])\n",
    "        df=df.join(zip_new,on='zip_code')\n",
    "        df.drop('zip_code',inplace=True,axis=1)\n",
    "        \n",
    "        #drop the features for which greater than 10% of the loans were missing data for\n",
    "        num_rows=df.count(axis=0)\n",
    "        df=df.iloc[:,(num_rows>=0.9*len(df)).tolist()]\n",
    "        #drop the observation that was missing for any field\n",
    "        df=df.dropna(axis=0,how='any')\n",
    "       \n",
    "        \n",
    "        #label the dataset to create y\n",
    "        y=df['loan_status']\n",
    "        df=df.drop(['loan_status'],axis=1)    \n",
    "        return df,y\n",
    "    \n",
    "    '''\n",
    "    The following part is updated by Yufei Gao on 3/29\n",
    "    The main purpose is to deal with the imbalance dataset\n",
    "    \n",
    "    '''\n",
    "    #we firstly simplify this problem to use only for categories:\n",
    "    #fully paid, grace period, late and charged off\n",
    "    \n",
    "    def simplify_status(loan_data):\n",
    "        #does not meet policy: fully paid, can be also considered as fully paid\n",
    "        loan_data['loan_status'].replace(2,1,inplace = True)\n",
    "        #does not meet policy: charged off, can be also considered as charged off\n",
    "        loan_data['loan_status'].replace(3,8,inplace = True)\n",
    "        #Default merged to charged off\n",
    "        loan_data['loan_status'].replace(7,8,inplace = True)\n",
    "        #merge those \"late\" status\n",
    "        loan_data['loan_status'].replace(6,5,inplace = True)\n",
    "        \n",
    "        #By doing these, we have 1-fully paid, 4-grace period\n",
    "        # 5-late, and 8-charged off\n",
    "        #Then we can renumber these categories, as:\n",
    "        #1-fully paid, 2-grace period, 3-late, 4-charged off\n",
    "        loan_data['loan_status'].replace(4,2,inplace = True)\n",
    "        loan_data['loan_status'].replace(8,4,inplace = True)\n",
    "        loan_data['loan_status'].replace(5,3,inplace = True)\n",
    "        return loan_data\n",
    "                \n",
    "            \n",
    "    \n",
    "    #calculate the distribution in the column: loan_status\n",
    "    def calculate_status(df):\n",
    "        dic1={}\n",
    "        for val in df['loan_status']:\n",
    "            if val in dic1:\n",
    "                dic1[val] += 1;\n",
    "            else:\n",
    "                dic1[val] = 1;\n",
    "        return dic1\n",
    "    \n",
    "    #one method to deal with the imbalance dataset is to cut some samples\n",
    "    #which belong to the major categories\n",
    "    #input variables: the dataset, calculation based on each status\n",
    "    #and remain number for the category 1\n",
    "    \n",
    "    def imbalance_cut(df, dic, remain_perc):\n",
    "        #seperate the df based on loan status\n",
    "        #notice that the number of 1 and 4 is too large\n",
    "        df1 = df[df['loan_status'] == 1]\n",
    "        df2 = df[df['loan_status'] == 2]\n",
    "        df3 = df[df['loan_status'] == 3]\n",
    "        df4 = df[df['loan_status'] == 4]\n",
    "        \n",
    "        remain_num1 = int(remain_perc * dic[1])\n",
    "        remain_num4 = remain_num1\n",
    "        #split those 2 categories randomly\n",
    "        df1= df1.sample(remain_num1, replace=True)\n",
    "        df4= df4.sample(remain_num4, replace=True)\n",
    "        \n",
    "        frames = []\n",
    "        #concate all left\n",
    "        frames.append(df1)\n",
    "        frames.append(df2)\n",
    "        frames.append(df3)\n",
    "        frames.append(df4)\n",
    "        loan_data = pd.concat(frames)\n",
    "        return loan_data\n",
    "    \n",
    "    #the other method is to duplicate the category with relatively small total numbers\n",
    "    def imbalance_dup(df, dic, dup_times):\n",
    "        #seperate the df based on loan status\n",
    "        #notice that the number of 1 and 4 is too large\n",
    "        #other categories are relativly small size\n",
    "        df1 = df[df['loan_status'] == 1]\n",
    "        df2 = df[df['loan_status'] == 2]\n",
    "        df3 = df[df['loan_status'] == 3]\n",
    "        df4 = df[df['loan_status'] == 4]\n",
    "        \n",
    "        #duplicate those categories for several times\n",
    "        #try to make sure their size are closed to each other\n",
    "        frames = []\n",
    "        for times in range(dup_times):          \n",
    "            frames.append(df2)\n",
    "        for times in range(int(dup_times*dic[2]/dic[3])):\n",
    "            frames.append(df3)            \n",
    "        \n",
    "        frames.append(df1)\n",
    "        frames.append(df4)\n",
    "        loan_data = pd.concat(frames)\n",
    "        return loan_data\n",
    "    \n",
    "    #the third method is to combine cut and duplication\n",
    "    #that is, we cut the size of cate 1 and 8 while duplicate other categories\n",
    "    def imblance_cut_dup(self, df, dic, remain_perc, dup_times):\n",
    "        loan_data = self.imbalance_cut(df, dic, remain_perc)\n",
    "        loan_data = self.imbalance_dup(loan_data, dic, dup_times)\n",
    "        \n",
    "        dic1={}\n",
    "        for val in loan_data['loan_status']:\n",
    "            if val in dic1:\n",
    "                dic1[val] += 1;\n",
    "            else:\n",
    "                dic1[val] = 1;\n",
    "        print \"the current distribution:\"\n",
    "        print dic1\n",
    "        return loan_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is a test for these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LARGE_FILE = \"C:\\Users\\Administrator\\Desktop\\practicum_regression\\loan_data_no_current_converted.csv\"\n",
    "CHUNKSIZE = 100000 # processing 100,000 rows at a time\n",
    "reader = pd.read_csv(LARGE_FILE, chunksize=CHUNKSIZE, low_memory=False)\n",
    "frames = []\n",
    "for df in reader:\n",
    "    frames.append(df)\n",
    "loan_data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simplify_status(loan_data):\n",
    "    loan_data['loan_status'].replace(2,1,inplace = True)\n",
    "    loan_data['loan_status'].replace(3,8,inplace = True)\n",
    "    loan_data['loan_status'].replace(7,8,inplace = True)\n",
    "    loan_data['loan_status'].replace(6,5,inplace = True)\n",
    "    loan_data['loan_status'].replace(4,2,inplace = True)\n",
    "    loan_data['loan_status'].replace(8,4,inplace = True)\n",
    "    loan_data['loan_status'].replace(5,3,inplace = True)\n",
    "    return loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_status(df):\n",
    "        dic1={}\n",
    "        for val in df['loan_status']:\n",
    "            if val in dic1:\n",
    "                dic1[val] += 1;\n",
    "            else:\n",
    "                dic1[val] = 1;\n",
    "        return dic1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    def imbalance_cut(df, dic, remain_perc):\n",
    "        #seperate the df based on loan status\n",
    "        #notice that the number of 1 and 4 is too large\n",
    "        df1 = df[df['loan_status'] == 1]\n",
    "        df2 = df[df['loan_status'] == 2]\n",
    "        df3 = df[df['loan_status'] == 3]\n",
    "        df4 = df[df['loan_status'] == 4]\n",
    "        \n",
    "        remain_num1 = int(remain_perc * dic[1])\n",
    "        remain_num4 = remain_num1\n",
    "        #split those 2 categories randomly\n",
    "        df1= df1.sample(remain_num1, replace=True)\n",
    "        df4= df4.sample(remain_num4, replace=True)\n",
    "        \n",
    "        frames = []\n",
    "        #concate all left\n",
    "        frames.append(df1)\n",
    "        frames.append(df2)\n",
    "        frames.append(df3)\n",
    "        frames.append(df4)\n",
    "        loan_data = pd.concat(frames)\n",
    "        return loan_data\n",
    "    \n",
    "    #the other method is to duplicate the category with relatively small total numbers\n",
    "    def imbalance_dup(df, dic, dup_times):\n",
    "        #seperate the df based on loan status\n",
    "        #notice that the number of 1 and 4 is too large\n",
    "        #other categories are relativly small size\n",
    "        df1 = df[df['loan_status'] == 1]\n",
    "        df2 = df[df['loan_status'] == 2]\n",
    "        df3 = df[df['loan_status'] == 3]\n",
    "        df4 = df[df['loan_status'] == 4]\n",
    "        \n",
    "        #duplicate those categories for several times\n",
    "        #try to make sure their size are closed to each other\n",
    "        frames = []\n",
    "        for times in range(dup_times):          \n",
    "            frames.append(df2)\n",
    "        for times in range(int(dup_times*dic[2]/dic[3])):\n",
    "            frames.append(df3)            \n",
    "        \n",
    "        frames.append(df1)\n",
    "        frames.append(df4)\n",
    "        loan_data = pd.concat(frames)\n",
    "        return loan_data\n",
    "    \n",
    "    #the third method is to combine cut and duplication\n",
    "    #that is, we cut the size of cate 1 and 8 while duplicate other categories\n",
    "    def imblance_cut_dup(df, dic, remain_perc, dup_times):\n",
    "        loan_data = imbalance_cut(df, dic, remain_perc)\n",
    "        loan_data = imbalance_dup(loan_data, dic, dup_times)\n",
    "        \n",
    "        dic1={}\n",
    "        for val in loan_data['loan_status']:\n",
    "            if val in dic1:\n",
    "                dic1[val] += 1;\n",
    "            else:\n",
    "                dic1[val] = 1;\n",
    "        print \"the current distribution:\"\n",
    "        print dic1\n",
    "        return loan_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 673688, 2: 1988, 3: 761, 4: 12125, 5: 5605, 6: 22452, 7: 119, 8: 175085}\n",
      "new fully paid: 675676\n",
      "new charged off: 175965\n",
      "grace: 12125\n",
      "late: 28057\n"
     ]
    }
   ],
   "source": [
    "dic = calculate_status(loan_data)\n",
    "print dic\n",
    "print \"new fully paid:\",dic[1]+dic[2]\n",
    "print \"new charged off:\",dic[7]+dic[3]+dic[8]\n",
    "print \"grace:\",dic[4]\n",
    "print \"late:\",dic[5]+dic[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the function \"simplify_status\" to merge some status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_data_copy = loan_data.copy()\n",
    "loan_data_copy = simplify_status(loan_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 675676, 2: 12125, 3: 28057, 4: 175965}\n"
     ]
    }
   ],
   "source": [
    "dic1 = calculate_status(loan_data_copy)\n",
    "print dic1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can find that the number of each status perfectly matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the current distribution:\n",
      "{1: 67567, 2: 72750, 3: 56114, 4: 67567}\n"
     ]
    }
   ],
   "source": [
    "loan_data_copy = imblance_cut_dup(loan_data_copy, dic1, 0.1, 6)\n",
    "#remain 10% of the status 1, and duplicate type 2 for 6 times\n",
    "# dict1 is definded above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The new distribution of the 4 status"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
