{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncreated by Yufei Gao at 4/12/2018\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "created by Yufei Gao at 4/12/2018\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_proc():\n",
    "    \n",
    "    def process_zip():\n",
    "        #dealing with zipcode\n",
    "        zip_data=pd.read_csv('ZIP.csv')\n",
    "        zip_data['Zip']=zip_data['Zip'].astype(str)\n",
    "        for i in range(len(zip_data['Zip'])):\n",
    "            if len(zip_data['Zip'][i])==4:\n",
    "                zip_data['Zip'][i]='0'+zip_data['Zip'][i]\n",
    "        zip_data['Zip']=[zip_data['Zip'][i][0:3] for i in range(len(zip_data))] \n",
    "        zip_data.iloc[:,-3:]=zip_data[['Median','Mean','Pop']].apply(lambda x: x.str.replace(',',''))\n",
    "        for i in range(1,4):\n",
    "            zip_data.iloc[:,-i]=pd.to_numeric(zip_data.iloc[:,-i],errors='coerce')\n",
    "        zip_data['weight']=zip_data['Pop']/zip_data.groupby('Zip')['Pop'].transform(sum)\n",
    "        zip_data['new_mean']=zip_data['Mean']*zip_data['weight']\n",
    "        zip_data['new_median']=zip_data['Median']*zip_data['weight']\n",
    "        zip_new=pd.DataFrame()\n",
    "        zip_new=zip_data.groupby('Zip')['new_mean','new_median'].sum()\n",
    "        return zip_new\n",
    "        \n",
    "    def readcsv():\n",
    "        LARGE_FILE = \"C:\\\\Users\\Administrator\\Desktop\\practicum_regression\\loan_data_no_current_converted.csv\"\n",
    "        CHUNKSIZE = 100000 # processing 100,000 rows at a time\n",
    "        reader = pd.read_csv(LARGE_FILE, chunksize=CHUNKSIZE, low_memory=False)\n",
    "        frames = []\n",
    "        for df in reader:\n",
    "            frames.append(df)\n",
    "        loan_data = pd.concat(frames)\n",
    "        return loan_data   \n",
    "    def cleaning(df,zip_new,keep_desc=True,categorical_to_binary=True):\n",
    "        df=df.dropna(axis=0,how='all')\n",
    "        drop_list=['emp_title','title','earliest_cr_line','desc','issue_d','id','member_id','url','grade','sub_grade',\n",
    "                   'int_rate','avg_cur_bal','addr_state','funded_amnt','funded_amnt_inv','collection_recovery_fee',\n",
    "                   'collections_12_mths_ex_med','mths_since_last_major_derog','next_pymnt_d','recoveries','total_pymnt',\n",
    "                   'total_pymnt_inv','total_rec_int','issue_d',' last_credit_pull_d','last_pymnt_d','last_credit_pull_d',\n",
    "                  'total_rec_prncp','settlement_status','hardship_loan_status','hardship_status','debt_settlement_flag',\n",
    "                   'verification_status','total_rec_late_fee']\n",
    "        df.drop(drop_list,inplace=True,axis=1,errors='ignore')\n",
    "        #deal with percentage mark\n",
    "        df['revol_util']=df['revol_util'].replace('%','',regex=True).astype('float')/100\n",
    "        #merge zipcode with census data\n",
    "        df['zip_code']=df['zip_code'].apply(lambda x: x[:3])\n",
    "        df=df.join(zip_new,on='zip_code')\n",
    "        df.drop('zip_code',inplace=True,axis=1)\n",
    "        #drop the observation that was missing for ALL field\n",
    "        df=df.dropna(axis=0,how='all')\n",
    "        #drop the features for which greater than 10% of the loans were missing data for\n",
    "        num_rows=df.count(axis=0)\n",
    "        df=df.iloc[:,(num_rows>=0.9*len(df)).tolist()]\n",
    "        #drop the observation that was missing for any field\n",
    "        df=df.dropna(axis=0,how='any')\n",
    "        #label the dataset to create y\n",
    "        #0:fully paid, does not meet policy:fully paid\n",
    "        #1:Does not meet the credit policy. Status:Charged Off\",default,charge of\n",
    "        df=df[(True^df['loan_status'].isin([4]))] \n",
    "        df=df[(True^df['loan_status'].isin([5]))]\n",
    "        df=df[(True^df['loan_status'].isin([6]))] \n",
    "        #label the dataset to create y\n",
    "        y=df['loan_status'].replace(1,0)\n",
    "        y=y.replace(2,0)\n",
    "        y=y.replace(3,1)\n",
    "        y=y.replace(7,1)\n",
    "        y=y.replace(8,1)\n",
    "        df=df.drop(['loan_status'],axis=1) \n",
    "        return df,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipdata = data_proc.process_zip()\n",
    "df = data_proc.readcsv()\n",
    "x,y = data_proc.cleaning(df,zipdata,keep_desc=False,categorical_to_binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772086, 772086)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loan_amnt\n",
      "term\n",
      "installment\n",
      "emp_length\n",
      "home_ownership\n",
      "annual_inc\n",
      "pymnt_plan\n",
      "purpose\n",
      "dti\n",
      "delinq_2yrs\n",
      "inq_last_6mths\n",
      "open_acc\n",
      "pub_rec\n",
      "revol_bal\n",
      "revol_util\n",
      "total_acc\n",
      "initial_list_status\n",
      "out_prncp\n",
      "out_prncp_inv\n",
      "last_pymnt_amnt\n",
      "policy_code\n",
      "application_type\n",
      "acc_now_delinq\n",
      "tot_coll_amt\n",
      "tot_cur_bal\n",
      "total_rev_hi_lim\n",
      "acc_open_past_24mths\n",
      "bc_open_to_buy\n",
      "bc_util\n",
      "chargeoff_within_12_mths\n",
      "delinq_amnt\n",
      "mo_sin_old_rev_tl_op\n",
      "mo_sin_rcnt_rev_tl_op\n",
      "mo_sin_rcnt_tl\n",
      "mort_acc\n",
      "mths_since_recent_bc\n",
      "num_accts_ever_120_pd\n",
      "num_actv_bc_tl\n",
      "num_actv_rev_tl\n",
      "num_bc_sats\n",
      "num_bc_tl\n",
      "num_il_tl\n",
      "num_op_rev_tl\n",
      "num_rev_accts\n",
      "num_rev_tl_bal_gt_0\n",
      "num_sats\n",
      "num_tl_30dpd\n",
      "num_tl_90g_dpd_24m\n",
      "num_tl_op_past_12m\n",
      "pct_tl_nvr_dlq\n",
      "percent_bc_gt_75\n",
      "pub_rec_bankruptcies\n",
      "tax_liens\n",
      "tot_hi_cred_lim\n",
      "total_bal_ex_mort\n",
      "total_bc_limit\n",
      "total_il_high_credit_limit\n",
      "hardship_flag\n",
      "hardship_type\n",
      "hardship_reason\n",
      "disbursement_method\n",
      "new_mean\n",
      "new_median\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature=[]\n",
    "for key, value in x.iteritems():\n",
    "    feature.append(key)\n",
    "    print (key)\n",
    "len(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Logistic Regression(Ridge) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Binary logistic regression\n",
    "class log_reg():\n",
    "    # Evaluate the model by splitting into train and test sets\n",
    "    def split(x,y,rand=0):\n",
    "        \n",
    "        y = np.ravel(y)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25,random_state=rand)\n",
    "        \n",
    "        return x_train, x_test, y_train, y_test \n",
    "    #we need to add validation dataset here\n",
    "    \n",
    "    # Find binary column method one\n",
    "    def bool_cols(df,isbool=True):\n",
    "        bool_cols=[]\n",
    "        for col in df:\n",
    "            if isbool==True:\n",
    "                if df[col].dropna().value_counts().index.isin([0,1]).all():\n",
    "                    bool_cols.append(col)\n",
    "            else:\n",
    "                if not df[col].dropna().value_counts().index.isin([0,1]).all():\n",
    "                    bool_cols.append(col)\n",
    "        return bool_cols\n",
    "    # this above step is to facilitate normalization later\n",
    "    # method two\n",
    "    def not_bi(x):\n",
    "        not_bi=[]\n",
    "        for i in list(x):\n",
    "            u=x[i].unique()\n",
    "            if not (0 in u and 1 in u and len(u)==2): #if not binary\n",
    "                not_bi.append(i)\n",
    "        return not_bi\n",
    "    \n",
    "    def reg(x_train, y_train, c, num_iter):\n",
    "           \n",
    "        model = LogisticRegression(penalty='l2',class_weight='balanced',solver='sag',n_jobs=-1, C=c, max_iter = num_iter)\n",
    "        \n",
    "        \"\"\"\n",
    "        Why we need standardize?\n",
    "        \n",
    "        Note that ‘sag’ and ‘saga’ fast convergence is only guaranteed on features \n",
    "        with approximately the same scale. You can preprocess the data with \n",
    "        a scaler from sklearn.preprocessing.\n",
    "        \"\"\"\n",
    "        \n",
    "        model = model.fit(x_train, y_train)\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def ModelValuation(x_test,y_test,model):\n",
    "        \n",
    "        probs = model.predict_proba(x_test)\n",
    "        #fpr, tpr, thresholds = metrics.roc_curve(y_test, probs[:, 1])\n",
    "        \n",
    "        #plt.figure(1)\n",
    "        #plt.plot(fpr, tpr, label='LogisticRegression')\n",
    "        #plt.xlabel('False positive rate')\n",
    "        #plt.ylabel('True positive rate')\n",
    "        #plt.title('ROC curve')\n",
    "        #plt.legend(loc='best')\n",
    "        #plt.show()\n",
    "        \n",
    "        #print(\"Area Under the Curve (AUC) from prediction score is %f\" % metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "    \n",
    "        return None  \n",
    "    \n",
    "    def y_pred(x_test,threshold=0.5):\n",
    "        \n",
    "        if threshold == 0.5:\n",
    "            y_predicted = model.predict(x_test)\n",
    "        else:\n",
    "            probs = model.predict_proba(x_test)\n",
    "            y_predicted = np.array(probs[:,1] >= threshold).astype(int)\n",
    "        \n",
    "        return y_predicted    \n",
    "    \n",
    "    def GetScores(y_test,y_predicted):\n",
    "        #G means score \n",
    "        CM = metrics.confusion_matrix(y_test, y_predicted)\n",
    "        TN = CM[0,0]\n",
    "        FN = CM[1,0]\n",
    "        TP = CM[1,1]\n",
    "        FP = CM[0,1]\n",
    "        \n",
    "        sensitivity = float(TP)/float(TP+FN)\n",
    "        specificity = float(TN)/float(TN+FP)\n",
    "        G = np.sqrt(sensitivity*specificity)\n",
    "        #print(\"G score is %f\" % G)\n",
    "        #print(\"Specificity is %f\" % specificity)\n",
    "        \n",
    "        # Generate and display different evaluation metrics\n",
    "        print(\"Mean accuracy score is %f\" % metrics.accuracy_score(y_test, y_predicted))\n",
    "          \n",
    "        #print(\"Confusion Marix\")\n",
    "        #print(CM)\n",
    "        \n",
    "        return specificity , G\n",
    "        \n",
    "    # Convenience function to plot confusion matrix\n",
    "    def confusion(y_test,y_predicted,title):\n",
    "        \n",
    "        # Define names for the three Iris types\n",
    "        names = ['Default', 'Not Default']\n",
    "    \n",
    "        # Make a 2D histogram from the test and result arrays\n",
    "        pts, xe, ye = np.histogram2d(y_test, y_predicted, bins=2)\n",
    "    \n",
    "        # For simplicity we create a new DataFrame\n",
    "        pd_pts = pd.DataFrame(pts.astype(int), index=names, columns=names )\n",
    "        \n",
    "        # Display heatmap and add decorations\n",
    "        hm = sns.heatmap(pd_pts, annot=True, fmt=\"d\")\n",
    "        hm.axes.set_title(title)\n",
    "        \n",
    "        return None\n",
    "            \n",
    "    def find_threshold(x_test,y_test):\n",
    "    \n",
    "        probs = model.predict_proba(x_test)\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, probs[:, 1])\n",
    "        \n",
    "        sensitivity = tpr\n",
    "        specificity = 1 - fpr\n",
    "        G = np.sqrt(sensitivity*specificity)\n",
    "        \n",
    "        plt.figure(2)\n",
    "        plt.plot(thresholds,G)\n",
    "        plt.xlabel('Thresholds')\n",
    "        plt.ylabel('G-Scores')\n",
    "        plt.title('G-Scores with different thresholds')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        print(\"The highest G score is %f with threshold at %f\" % (np.amax(G),thresholds[np.argmax(G)]) )\n",
    "        \n",
    "        return thresholds[np.argmax(G)]\n",
    "    # this is just testing, we add weight so we don't need to adjust threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Binary logistic Regression(Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_dataset(df, y, n, m):\n",
    "    y=pd.Series(y)\n",
    "    # by calling the function split, y will become array type\n",
    "    interval_len=int(len(df)/n)\n",
    "    if m == 1:\n",
    "        x_test = df.iloc[0:interval_len]\n",
    "        y_test = y.iloc[0:interval_len]\n",
    "        x_train = df.iloc[interval_len:len(df)]\n",
    "        y_train = y.iloc[interval_len:len(df)]\n",
    "    elif m == n:\n",
    "        x_test = df.iloc[(n-1)*interval_len:len(df)]\n",
    "        y_test = y.iloc[(n-1)*interval_len:len(df)]\n",
    "        x_train = df.iloc[0:(n-1)*interval_len]\n",
    "        y_train = y.iloc[0:(n-1)*interval_len]\n",
    "    else:\n",
    "        x_test = df.iloc[(m-1)*interval_len:m*interval_len]\n",
    "        x_train1 = df.iloc[0:(m-1)*interval_len]\n",
    "        x_train2 = df.iloc[m*interval_len:len(df)]\n",
    "        frames1 = [x_train1, x_train2]\n",
    "        x_train = pd.concat(frames1)\n",
    "        \n",
    "        y_test = y.iloc[(m-1)*interval_len:m*interval_len]\n",
    "        y_train1 = y.iloc[0:(m-1)*interval_len]\n",
    "        y_train2 = y.iloc[m*interval_len:len(df)]\n",
    "        frames2 = [y_train1, y_train2]\n",
    "        y_train = pd.concat(frames2)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_choice(df, y, n):\n",
    "    if (len(df) % n != 0):\n",
    "        df1 = df[0:len(df)-len(df)%n]\n",
    "        y1 = y[0:len(y)-len(y)%n]\n",
    "    return df1, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split , cross_val_score\n",
    "def split(x,y,rand=0):\n",
    "        \n",
    "        y = np.ravel(y)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25,random_state=rand)\n",
    "        \n",
    "        return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part we focus on validation on a fixed test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=drop_choice(x, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772080, 772080)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.833024\n",
      "Mean accuracy score is 0.837454\n",
      "Mean accuracy score is 0.832879\n",
      "Mean accuracy score is 0.832605\n",
      "Mean accuracy score is 0.832765\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalize\n",
    "for i in range(1,6):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "\n",
    "    x_train_temp, x_test, y_train_temp, y_test = log_reg.split(x,y,rand=0)\n",
    "\n",
    "    x_train, x_val_test, y_train, y_val_test = validation_dataset(x_train_temp,y_train_temp,5,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,1.0,100)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose a very small C=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.830501\n",
      "Mean accuracy score is 0.832176\n",
      "Mean accuracy score is 0.833178\n",
      "Mean accuracy score is 0.833990\n",
      "Mean accuracy score is 0.832073\n",
      "Mean accuracy score is 0.834629\n",
      "Mean accuracy score is 0.835233\n",
      "Mean accuracy score is 0.830311\n",
      "Mean accuracy score is 0.832556\n",
      "Mean accuracy score is 0.831606\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "for i in range(1,11):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "    # x_test_real and y_test_real is the true test set\n",
    "    # in the turning parameter process, we will not use the test set at this moment\n",
    "    # notice that the rand state must be hold \n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "    # in this part, we cut the train into the real train and validation set\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,10,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,0.01,100)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a smaller C(C=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this part only shows you the mean accuracy metric, if you want other metric, just cancel the notation in the regresson class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will take 20-30 min to run next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.830415\n",
      "Mean accuracy score is 0.832228\n",
      "Mean accuracy score is 0.833264\n",
      "Mean accuracy score is 0.834646\n",
      "Mean accuracy score is 0.832090\n",
      "Mean accuracy score is 0.834611\n",
      "Mean accuracy score is 0.835406\n",
      "Mean accuracy score is 0.830259\n",
      "Mean accuracy score is 0.832936\n",
      "Mean accuracy score is 0.831606\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "for i in range(1,11):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "    # x_test_real and y_test_real is the true test set\n",
    "    # in the turning parameter process, we will not use the test set at this moment\n",
    "    # notice that the rand state must be hold \n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "    # in this part, we cut the train into the real train and validation set\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,10,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,0.1,100)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.830259\n",
      "Mean accuracy score is 0.832176\n",
      "Mean accuracy score is 0.833247\n",
      "Mean accuracy score is 0.834784\n",
      "Mean accuracy score is 0.832124\n",
      "Mean accuracy score is 0.834629\n",
      "Mean accuracy score is 0.835354\n",
      "Mean accuracy score is 0.830311\n",
      "Mean accuracy score is 0.832867\n",
      "Mean accuracy score is 0.831572\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "for i in range(1,11):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "    # x_test_real and y_test_real is the true test set\n",
    "    # in the turning parameter process, we will not use the test set at this moment\n",
    "    # notice that the rand state must be hold \n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "    # in this part, we cut the train into the real train and validation set\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,10,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,1,100)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.830277\n",
      "Mean accuracy score is 0.832176\n",
      "Mean accuracy score is 0.833247\n",
      "Mean accuracy score is 0.834836\n",
      "Mean accuracy score is 0.832107\n",
      "Mean accuracy score is 0.834629\n",
      "Mean accuracy score is 0.835354\n",
      "Mean accuracy score is 0.830294\n",
      "Mean accuracy score is 0.832867\n",
      "Mean accuracy score is 0.831572\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "for i in range(1,11):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "    # x_test_real and y_test_real is the true test set\n",
    "    # in the turning parameter process, we will not use the test set at this moment\n",
    "    # notice that the rand state must be hold \n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "    # in this part, we cut the train into the real train and validation set\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,10,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,2,100)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.830328\n",
      "Mean accuracy score is 0.832176\n",
      "Mean accuracy score is 0.833247\n",
      "Mean accuracy score is 0.834767\n",
      "Mean accuracy score is 0.832107\n",
      "Mean accuracy score is 0.834629\n",
      "Mean accuracy score is 0.835354\n",
      "Mean accuracy score is 0.830259\n",
      "Mean accuracy score is 0.832884\n",
      "Mean accuracy score is 0.831572\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "for i in range(1,11):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "    # x_test_real and y_test_real is the true test set\n",
    "    # in the turning parameter process, we will not use the test set at this moment\n",
    "    # notice that the rand state must be hold \n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "    # in this part, we cut the train into the real train and validation set\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,10,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,0.5,100)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a larger C (C=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.830294\n",
      "Mean accuracy score is 0.832176\n",
      "Mean accuracy score is 0.833247\n",
      "Mean accuracy score is 0.834836\n",
      "Mean accuracy score is 0.832107\n",
      "Mean accuracy score is 0.834629\n",
      "Mean accuracy score is 0.835354\n",
      "Mean accuracy score is 0.830311\n",
      "Mean accuracy score is 0.832867\n",
      "Mean accuracy score is 0.831589\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "for i in range(1,11):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "\n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,10,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,5,100)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose C = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.830277\n",
      "Mean accuracy score is 0.832159\n",
      "Mean accuracy score is 0.833247\n",
      "Mean accuracy score is 0.834836\n",
      "Mean accuracy score is 0.832107\n",
      "Mean accuracy score is 0.834629\n",
      "Mean accuracy score is 0.835354\n",
      "Mean accuracy score is 0.830294\n",
      "Mean accuracy score is 0.832850\n",
      "Mean accuracy score is 0.831572\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "\n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,10,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,10,100)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.830259\n",
      "Mean accuracy score is 0.832159\n",
      "Mean accuracy score is 0.833247\n",
      "Mean accuracy score is 0.834836\n",
      "Mean accuracy score is 0.832107\n",
      "Mean accuracy score is 0.834629\n",
      "Mean accuracy score is 0.835354\n",
      "Mean accuracy score is 0.830311\n",
      "Mean accuracy score is 0.832867\n",
      "Mean accuracy score is 0.831589\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,11):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "\n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,10,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,20,100)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a larger iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.837366\n",
      "Mean accuracy score is 0.840448\n",
      "Mean accuracy score is 0.839196\n",
      "Mean accuracy score is 0.837564\n",
      "Mean accuracy score is 0.837422\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "for i in range(1,6):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "\n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,5,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,1,500)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.831235\n",
      "Mean accuracy score is 0.836399\n",
      "Mean accuracy score is 0.833653\n",
      "Mean accuracy score is 0.832902\n",
      "Mean accuracy score is 0.832211\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "\n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,5,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,1,100)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "F:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "F:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "F:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy score is 0.833705\n",
      "Mean accuracy score is 0.838013\n",
      "Mean accuracy score is 0.835924\n",
      "Mean accuracy score is 0.835147\n",
      "Mean accuracy score is 0.834715\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,6):\n",
    "    not_bi = log_reg.not_bi(x)\n",
    "\n",
    "    x_train_temp, x_test_real, y_train_temp, y_test_real = log_reg.split(x,y,rand=0)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = validation_dataset(x_train_temp,y_train_temp,5,i)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[not_bi]) \n",
    "\n",
    "    x_train_scaled=x_train\n",
    "    x_test_scaled=x_test\n",
    "\n",
    "    x_train_scaled[not_bi] = scaler.transform(x_train[not_bi])\n",
    "    x_test_scaled[not_bi]  = scaler.transform(x_test[not_bi])\n",
    "\n",
    "# Fit model\n",
    "    model = log_reg.reg(x_train_scaled,y_train,1,200)\n",
    "# Evaluate model\n",
    "    log_reg.ModelValuation(x_test_scaled,y_test,model)\n",
    "    y_predicted = log_reg.y_pred(x_test_scaled,threshold=0.5)\n",
    "    spec , G = log_reg.GetScores(y_test,y_predicted)\n",
    "#log_reg.confusion(y_test,y_predicted,'Default Confusion Matrix')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
